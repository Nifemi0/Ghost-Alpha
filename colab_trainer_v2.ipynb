{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ§  Poly Prediction: Hybrid GPU Trainer\n",
                "\n",
                "This notebook is currently running on a **Google Colab Tesla T4 GPU**.\n",
                "\n",
                "### ðŸš€ One-Click Setup\n",
                "Since Colab is in the cloud and your code is on your server, we will pull everything we need right here."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "aa72815a",
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install sentence-transformers sqlalchemy pandas numpy torch\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import gc\n",
                "import os\n",
                "from sqlalchemy import create_engine\n",
                "from sentence_transformers import SentenceTransformer\n",
                "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU Type: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "632b272a",
            "metadata": {},
            "outputs": [],
            "source": [
                "### 1. Load Database (Google Drive Method)\n",
                "This connects to your Google Drive directly. \n",
                "**INSTRUCTIONS:**\n",
                "1. Download `poly.db.gz` from your server.\n",
                "2. Upload it to your **Google Drive** main folder (My Drive).\n",
                "3. Run this cell and authorize access."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "65fa3c43",
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "import shutil\n",
                "import os\n",
                "\n",
                "# Mount Google Drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Copy database from Drive to Colab Runtime\n",
                "# MAKE SURE you uploaded poly.db.gz to your Google Drive root folder!\n",
                "source_path = '/content/drive/MyDrive/poly.db.gz'\n",
                "dest_path = 'poly.db.gz'\n",
                "\n",
                "if os.path.exists(source_path):\n",
                "    print(\"Found poly.db.gz in Drive! Copying...\")\n",
                "    shutil.copy(source_path, dest_path)\n",
                "    \n",
                "    # Decompress\n",
                "    import gzip\n",
                "    print(\"Decompressing...\")\n",
                "    with gzip.open(dest_path, 'rb') as f_in:\n",
                "        with open('poly.db', 'wb') as f_out:\n",
                "            shutil.copyfileobj(f_in, f_out)\n",
                "    print(\"Success! Database is ready.\")\n",
                "else:\n",
                "    print(f\"Error: Could not find {source_path}. Please upload it to your Drive root!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Feature Engineering Logic\n",
                "We've moved the logic here so it doesn't need to 'import' from your local files."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def custom_engineer_features(db_path=\"poly.db\"):\n",
                "    engine = create_engine(f\"sqlite:///{db_path}\")\n",
                "    \n",
                "    print(\"Loading resolved events from database...\")\n",
                "    query = \"SELECT * FROM events WHERE outcome IS NOT NULL\"\n",
                "    df = pd.read_sql(query, engine, parse_dates=['start_time', 'end_time'])\n",
                "\n",
                "    if df.empty:\n",
                "        print(\"No resolved events found.\")\n",
                "        return None, None\n",
                "\n",
                "    print(f\"Engineering features for {len(df)} samples...\")\n",
                "    \n",
                "    df['time_to_event_days'] = (df['end_time'] - df['start_time']).dt.days\n",
                "    \n",
                "    print(\"Generating text embeddings (Batch Mode)...\")\n",
                "    st_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
                "    \n",
                "    summaries = df['news_summary'].fillna('').tolist()\n",
                "    all_embeddings = []\n",
                "    batch_size = 1000\n",
                "    \n",
                "    for i in range(0, len(summaries), batch_size):\n",
                "        batch = summaries[i:i + batch_size]\n",
                "        batch_emb = st_model.encode(batch, show_progress_bar=False)\n",
                "        all_embeddings.append(batch_emb)\n",
                "        gc.collect()\n",
                "    \n",
                "    embeddings = np.vstack(all_embeddings)\n",
                "    embedding_df = pd.DataFrame(embeddings, index=df.index, columns=[f'emb_{i}' for i in range(embeddings.shape[1])])\n",
                "    \n",
                "    category_dummies = pd.get_dummies(df['category'], prefix='cat')\n",
                "    numerical_features = df[['initial_price', 'volume', 'time_to_event_days']].fillna(0)\n",
                "    \n",
                "    features = pd.concat([numerical_features, category_dummies, embedding_df], axis=1)\n",
                "    features = features.apply(pd.to_numeric, errors='coerce').fillna(0).astype('float32')\n",
                "    \n",
                "    target = df['outcome'].astype(int)\n",
                "    return features, target\n",
                "\n",
                "features, target = custom_engineer_features()\n",
                "print(f\"Final Dataset Shape: {features.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Neural Architecture & Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class NeuralPredictor(nn.Module):\n",
                "    def __init__(self, input_dim):\n",
                "        super(NeuralPredictor, self).__init__()\n",
                "        self.network = nn.Sequential(\n",
                "            nn.Linear(input_dim, 128),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(128, 64),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.2),\n",
                "            nn.Linear(64, 32),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(32, 1),\n",
                "            nn.Sigmoid()\n",
                "        )\n",
                "    def forward(self, x): return self.network(x)\n",
                "\n",
                "def train_on_gpu(features, target):\n",
                "    X_train_pd, X_test_pd, y_train_pd, y_test_pd = train_test_split(features, target, test_size=0.2, random_state=42, stratify=target)\n",
                "    X_train = torch.FloatTensor(X_train_pd.values).to(device)\n",
                "    y_train = torch.FloatTensor(y_train_pd.values).view(-1, 1).to(device)\n",
                "    X_test = torch.FloatTensor(X_test_pd.values).to(device)\n",
                "    y_test = torch.FloatTensor(y_test_pd.values).view(-1, 1).to(device)\n",
                "\n",
                "    model = NeuralPredictor(features.shape[1]).to(device)\n",
                "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
                "    criterion = nn.BCELoss()\n",
                "    \n",
                "    print(\"Starting High-Speed GPU Training...\")\n",
                "    for epoch in range(20):\n",
                "        model.train()\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(X_train)\n",
                "        loss = criterion(outputs, y_train)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        if (epoch+1) % 5 == 0: print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f}\")\n",
                "\n",
                "    torch.save(model.state_dict(), \"model_colab.pt\")\n",
                "    print(\"Training Finished. Model saved as model_colab.pt\")\n",
                "    files.download(\"model_colab.pt\")\n",
                "\n",
                "train_on_gpu(features, target)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
